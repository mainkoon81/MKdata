{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## MLP_01\n",
    "---\n",
    "\n",
    "In this notebook, we train an MLP to classify images from the MNIST database.\n",
    "\n",
    "### 1. Load MNIST Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# use Keras to import pre-shuffled MNIST database\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"The MNIST database has a training set of %d examples.\" % len(X_train))\n",
    "print(\"The MNIST database has a test set of %d examples.\" % len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Visualize the First Six Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# plot first six training images\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(1, 6, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(str(y_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. View an Image in More Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def visualize_input(img, ax):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    width, height = img.shape\n",
    "    thresh = img.max()/2.5\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(round(img[x][y],2)), xy=(y,x),\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        color='white' if img[x][y]<thresh else 'black')\n",
    "\n",
    "fig = plt.figure(figsize = (12,12)) \n",
    "ax = fig.add_subplot(111)\n",
    "visualize_input(X_train[0], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. Rescale the Images by Dividing Every Pixel in Every Image by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# rescale [0,255] --> [0,1]\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. Encode Categorical Integer Labels Using a One-Hot Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# print first ten (integer-valued) training labels\n",
    "print('Integer-valued labels:')\n",
    "print(y_train[:10])\n",
    "\n",
    "# one-hot encode the labels\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# print first ten (one-hot) training labels\n",
    "print('One-hot labels:')\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6. Define the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 7. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 8. Calculate the Classification Accuracy on the Test Set (Before Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 9. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 10. Load the Model with the Best Classification Accuracy on the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "model.load_weights('mnist.model.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 11. Calculate the Classification Accuracy on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## CNN_01  \n",
    "---\n",
    "From your random image...visualize four activation maps in a CNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for canopy ?\n",
    "(base) C:\\Users\\Minkun> C:\\Users\\Minkun\\AppData\\Local\\Enthought\\Canopy\\User\\python.exe -m pip install --upgrade pip\n",
    "        \n",
    "(base) C:\\Users\\Minkun> C:\\Users\\Minkun\\AppData\\Local\\Enthought\\Canopy\\User\\python.exe -m pip install opencv-python\n",
    "        \n",
    "# for jupyter ?\n",
    "conda install -c menpo opencv ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "cv2.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import scipy.misc \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# TODO: Feel free to try out your own images here by changing img_path\n",
    "# to a file path to another image on your computer!\n",
    "img_path = '5WD.big intersections 0.jpg'\n",
    "\n",
    "# load color image \n",
    "bgr_img = cv2.imread(img_path)\n",
    "# convert to grayscale\n",
    "gray_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)\n",
    "# resize to smaller\n",
    "small_img = scipy.misc.imresize(gray_img, 0.3)\n",
    "\n",
    "# rescale entries to lie in [0,1]\n",
    "small_img = small_img.astype(\"float32\")/255\n",
    "\n",
    "# plot image\n",
    "plt.imshow(small_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "###2. Specify the Filters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Feel free to modify the numbers here, to try out another filter!# TODO: \n",
    "# Please don't change the size of the array ~ :D\n",
    "filter_vals = np.array([[-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1]])\n",
    "\n",
    "### do not modify the code below this line ###\n",
    "\n",
    "# define four filters\n",
    "filter_1 = filter_vals\n",
    "filter_2 = -filter_1\n",
    "filter_3 = filter_1.T\n",
    "filter_4 = -filter_3\n",
    "filters = [filter_1, filter_2, filter_3, filter_4]\n",
    "\n",
    "# visualize all filters\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(filters[i], cmap='gray')\n",
    "    ax.set_title('Filter %s' % str(i+1))\n",
    "    width, height = filters[i].shape\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(filters[i][x][y]), xy=(y,x),\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        color='white' if filters[i][x][y]<0 else 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### 3. Visualize the Activation Maps for Each Filter\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# plot image\n",
    "plt.imshow(small_img, cmap='gray')\n",
    "\n",
    "# define a neural network with a single convolutional layer with one filter\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(1, (4, 4), activation='relu', input_shape=(small_img.shape[0], small_img.shape[1], 1)))\n",
    "\n",
    "# apply convolutional filter and return output\n",
    "def apply_filter(img, index, filter_list, ax):\n",
    "    # set the weights of the filter in the convolutional layer to filter_list[i]\n",
    "    model.layers[0].set_weights([np.reshape(filter_list[i], (4,4,1,1)), np.array([0])])\n",
    "    # plot the corresponding activation map\n",
    "    ax.imshow(np.squeeze(model.predict(np.reshape(img, (1, img.shape[0], img.shape[1], 1)))), cmap='gray')\n",
    "\n",
    "# visualize all filters\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.subplots_adjust(left=0, right=1.5, bottom=0.8, top=1, hspace=0.05, wspace=0.05)\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(filters[i], cmap='gray')\n",
    "    ax.set_title('Filter %s' % str(i+1))\n",
    "\n",
    "# visualize all activation maps\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])\n",
    "    apply_filter(small_img, i, filters, ax)\n",
    "    ax.set_title('Activation Map for Filter %s' % str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## MLP_02\n",
    "---\n",
    "train an MLP to classify images from the CIFAR-10 database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "# load the pre-shuffled train and test data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the First 24 Training Images\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "for i in range(36):\n",
    "    ax = fig.add_subplot(3, 12, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rescale the Images by Dividing Every Pixel in Every Image by 255\n",
    "\n",
    "# rescale [0,255] --> [0,1]\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Break Dataset into Training, Testing, and Validation Sets\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# one-hot encode the labels\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# break training set into training and validation sets\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000]\n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# print shape of training set\n",
    "print('x_train shape:', x_train.shape)\n",
    "\n",
    "# print number of training, validation, and test images\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_valid.shape[0], 'validation samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the Model Architecture\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape = x_train.shape[1:]))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='MLP.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=20,\n",
    "          validation_data=(x_valid, y_valid), callbacks=[checkpointer], \n",
    "          verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the Model with the Best Classification Accuracy on the Validation Set\n",
    "\n",
    "model.load_weights('MLP.weights.best.hdf5')\n",
    "\n",
    "# evaluate and print test accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## CNN_02\n",
    "---\n",
    "train a CNN to classify images from the CIFAR-10 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the Model Architecture\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', \n",
    "                        input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=100,\n",
    "          validation_data=(x_valid, y_valid), callbacks=[checkpointer], \n",
    "          verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "model.load_weights('model.weights.best.hdf5')\n",
    "# evaluate and print test accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Some Predictions\n",
    "\n",
    "This may give you some insight into why the network is misclassifying certain objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get predictions on the test set\n",
    "y_hat = model.predict(x_test)\n",
    "\n",
    "# define text labels (source: https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot a random sample of test images, their predicted labels, and ground truth\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "for i, idx in enumerate(np.random.choice(x_test.shape[0], size=32, replace=False)):\n",
    "    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_test[idx]))\n",
    "    pred_idx = np.argmax(y_hat[idx])\n",
    "    true_idx = np.argmax(y_test[idx])\n",
    "    ax.set_title(\"{} ({})\".format(cifar10_labels[pred_idx], cifar10_labels[true_idx]),\n",
    "                 color=(\"green\" if pred_idx == true_idx else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
