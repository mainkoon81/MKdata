{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Project: Binary Classiﬁcation Of Sonar Returns\n",
    "Discover how to eﬀectively use the Keras library in your machine learning project by working through a binary classiﬁcation project step-by-step.\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\n",
    "\n",
    "The Sonar dataset describes **sonar chirp** returns bouncing off different surfaces. The **60 input** variables are the strength of the returns at different angles. It is a binary classiﬁcation problem that requires a model to differentiate rocks from metal cylinders. You can learn more about this dataset on the UCI Machine Learning repository. \n",
    "\n",
    "It is a well understood dataset. All of the variables are continuous and generally in the range of 0 to 1. The output variable is a string **M for metal** and **R for rock**, which will need to be converted to integers 1 and 0. The dataset contains **208 observations**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "\n",
       "       9  ...      51      52      53      54      55     56      57      58  \\\n",
       "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.018  0.0084  0.0090   \n",
       "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.014  0.0049  0.0052   \n",
       "\n",
       "       59  60  \n",
       "0  0.0032   R  \n",
       "1  0.0044   R  \n",
       "\n",
       "[2 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sonar.csv', header=None)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = df.values\n",
    "\n",
    "X = data[:, 0:60].astype(float)\n",
    "y = data[:, -1]\n",
    "\n",
    "encoder = LabelEncoder().fit(y)\n",
    "encoded_y = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define and compile a baseline model.\n",
    "We are going to use scikit-learn to evaluate the model using **stratified k-fold** cross-validation. This is a resampling technique that will provide an estimate of the performance of the model. To use Keras models with scikit-learn, we must use the **KerasClassifier()** wrapper. This class takes a function that creates and returns our neural network model. It also takes arguments that it will pass along to the call to **fit()** such as the number of **epochs** and the **batch_size**. \n",
    "\n",
    "Let’s start off by defining the function that creates our baseline model. Our model will have a single fully connected hidden layer with the same number of neurons as **input** variables. This is a good default starting point when creating neural networks on a new problem. \n",
    "- The weights are initialized using a **small Gaussian random number**. \n",
    "- The **Rectifier** activation function is used. \n",
    "- The output layer contains a single neuron in order to make predictions. It uses the **sigmoid** activation function in order to produce a probability output in the range of 0 to 1 that can easily and automatically be converted to crisp class values. \n",
    "- Finally, we are using the logarithmic loss function (binary crossentropy) during training, the preferred loss function for binary classification problems. The model also uses the efficient Adam optimization algorithm for gradient descent and accuracy metrics will be collected when the model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# (60 inputs -> 60 hidden -> 1 output)\n",
    "\n",
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluate model with standardized dataset\n",
    "We pass the number of training epochs to the KerasClassifier, again using reasonable default values. Verbose output is also turned off given that the model will be created 10 times for the 10-fold cross-validation being performed. The output showing the mean and standard deviation of the estimated accuracy of the model on **unseen data**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(baseline) -> mean:0.82 (+/-0.10)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=47)\n",
    "\n",
    "results = cross_val_score(estimator, X, encoded_y, cv=kfold)\n",
    "print('accuracy(baseline) -> mean:%.2f (+/-%.2f)' %(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Improve Performance With Data Preparation\n",
    "It is a good practice to prepare your data before modeling. Neural network models are especially suitable to **having consistent input values, both in scale and distribution**. An effective data preparation scheme for tabular data when building neural network models is **standardization**. This is where the data is rescaled such that **the mean value for each attribute is 0 and the standard deviation is 1**. This preserves **Gaussian-like distributions** whilst **normalizing the central tendencies** for each attribute. \n",
    "\n",
    "We can use scikit-learn to perform the **standardization** of our Sonar dataset using the **`StandardScaler()`** class.\n",
    "- Rather than performing the standardization on the entire dataset, it is good practice to **train the standardization procedure on the training data** within the pass of a cross-validation run and to use the trained standardization instance to prepare the unseen test fold. \n",
    "\n",
    "This makes standardization a step in model preparation in the cross-validation process and it prevents the algorithm having knowledge of unseen data during evaluation, knowledge that might be passed from the data preparation scheme like a crisper distribution. We can achieve this in scikit-learn using a **`Pipeline()`** class. The pipeline is a **wrapper that executes one or more models within a pass of the cross-validation procedure**. Here, we can deﬁne a pipeline with the StandardScaler followed by our neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(baseline) -> mean:0.86 (+/-0.08)\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline model with standardized dataset\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('MLP', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=47)\n",
    "\n",
    "results = cross_val_score(pipeline, X, encoded_y, cv=kfold)\n",
    "print('accuracy(baseline) -> mean:%.2f (+/-%.2f)' %(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Improve Performance With Tuning Topology \n",
    "There are many things to tune on a neural network, such as the **weight(kernel?) initialization**, **activation functions**, **optimization procedure** and so on. One aspect that may have an outsized effect is the structure of the network itself (network topology). \n",
    "\n",
    "From (60 inputs -> 60 hidden -> 1 output)\n",
    "\n",
    "In this section we take a look at two experiments on the **structure of the network**: making it smaller and making it larger. These are good experiments to perform when tuning a neural network on your problem.\n",
    ">a) Evaluate a Narrower Network (60 inputs -> 30 hidden -> 1 output)\n",
    ">- I suspect that there is a lot of redundancy in the input variables for this problem. The data describes the same signal from different angles. Perhaps some of those angles are more relevant than others. We can force a type of feature extraction by the network **by restricting the representational space** in the ﬁrst hidden layer. \n",
    ">- In this experiment, **we take our baseline model with 60 neurons in the hidden layer and reduce it by half to 30**. This will put pressure on the network during training **to pick out the most important structure in the input data** to model. We will also standardize the data (as in the previous experiment with data preparation) and try to take advantage of the **small lift** in performance.\n",
    "\n",
    ">b) Evaluate a Deeper Network (60 inputs -> 60 hidden -> 30 hidden -> 1 output)\n",
    ">- Next, A neural network topology with **more layers** offers more opportunity for the network to **extract key features and recombine them in useful nonlinear ways**. We can evaluate whether adding more layers to the network improves the performance easily by making another small tweak to the function used to create our model. Here, we add one new layer to the network that introduces another hidden layer with 30 neurons after the ﬁrst hidden layer. \n",
    ">- The idea here is that the network is given the opportunity to model all input variables before being bottlenecked and forced to halve the representational capacity, much like we did in the experiment above with the smaller network. **Instead of squeezing the representation of the inputs themselves, we have an additional hidden layer to aid in the process**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(baseline) -> mean:0.87 (+/-0.10)\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification with Sonar Dataset: Standardized Narrower (60 inputs -> 30 hidden -> 1 output)\n",
    "\n",
    "def create_baseline_small():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=60, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('MLP', KerasClassifier(build_fn=create_baseline_small, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=47)\n",
    "\n",
    "results = cross_val_score(pipeline, X, encoded_y, cv=kfold)\n",
    "print('accuracy(baseline) -> mean:%.2f (+/-%.2f)' %(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "we have a very slight boost in the mean estimated accuracy and an important reduction in the standard deviation (average spread) of the accuracy scores for the model. This is a great result because we are doing slightly better with a network half the size, which in turn takes half the time to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(baseline) -> mean:0.85 (+/-0.09)\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification with Sonar Dataset: Standardized Deeper (60 inputs -> [60 -> 30] hidden -> 1 output) \n",
    "\n",
    "def create_baseline_large():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(30, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='normal'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('MLP', KerasClassifier(build_fn=create_baseline_large, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=47)\n",
    "\n",
    "results = cross_val_score(pipeline, X, encoded_y, cv=kfold)\n",
    "print('accuracy(baseline) -> mean:%.2f (+/-%.2f)' %(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "We do not get a lift in the model performance. This may be statistical noise or **a sign that further training is needed**. With further tuning of aspects like the **optimization algorithm** and the number of training **epochs**, it is expected that further improvements are possible. What is the best score that you can achieve on this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
