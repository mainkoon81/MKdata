{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Project: Regression Of Boston House Prices\n",
    "Discover how to develop and evaluate neural network models using Keras for a regression problem.\n",
    "\n",
    "The Boston house price describes properties of houses in Boston suburbs and is concerned with **modeling the price of houses** in those suburbs in thousands of dollars. As such, this is a regression predictive modeling problem. There are **13 input** variables that describe the properties of a given Boston suburb. The full list of attributes in this dataset are as follows:\n",
    "- CRIM: per capita crime rate by town.\n",
    "- ZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS: proportion of non-retail business acres per town.\n",
    "- CHAS: Charles River dummy variable ('1' if tract bounds river; '0' otherwise).\n",
    "- NOX: nitric oxides concentration (parts per 10 million).\n",
    "- RM: average number of rooms per dwelling\n",
    "- AGE: proportion of owner-occupied units built prior to 1940.\n",
    "- DIS: weighted distances to five Boston employment centers.\n",
    "- RAD: index of accessibility to radial highways.\n",
    "- TAX: full-value property-tax rate per USD 10,000.\n",
    "- PTRATIO: pupil-teacher ratio by town. \n",
    "- B: 1000(Bk−0.63)^2 where Bk is the proportion of blacks by town. \n",
    "- LSTAT: % lower status of the population.\n",
    "- MEDV: Median value of owner-occupied homes (in USD 1000s).\n",
    "\n",
    "This is a well studied problem in machine learning. It is convenient to work with because all of the input and output attributes are numerical and there are **506 instances** to work with. Reasonable performance for models evaluated using **Mean Squared Error (MSE)** are around 20 in squared thousands of dollars (or USD 4,500 if you take the square root). This is a nice target to aim for with our neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor #####\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.9</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.9</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2   3      4      5     6       7   8      9     10  \\\n",
       "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "\n",
       "      11    12    13  \n",
       "0  396.9  4.98  24.0  \n",
       "1  396.9  9.14  21.6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('housing.csv', delim_whitespace=True, header=None)\n",
    "data = df.values\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[:, 0:13]\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Develop a Baseline Neural Network Model\n",
    "We can create Keras models and evaluate them with scikit-learn by using handy **wrapper** objects provided by the Keras library. This is desirable, because scikit-learn excels at evaluating models and will allow us to use powerful data preparation and model evaluation schemes with very few lines of code. \n",
    "- The Keras wrapper class require a function as an argument. This function that we must deﬁne is responsible for creating the neural network model to be evaluated. The Keras wrapper object for use in scikit-learn as a regression estimator is called **`KerasRegressor()`**\n",
    "\n",
    "Below we deﬁne the function to create the baseline model to be evaluated. It is a simple model that has a single fully connected hidden layer with the same number of neurons as **input attributes(13)**. The network uses good practices such as the rectifier activation function for the hidden layer. **No activation function is used for the output layer** because it is a regression problem and we are interested in predicting numerical values directly without transform. \n",
    "- The efficient **ADAM optimization algorithm** is used. \n",
    "- **mean squared error loss function** is optimized. \n",
    "- This will be the same metric that we will use to evaluate the performance of the model. MSE is a desirable metric because by taking the square root of an error value it gives us a result that we can directly understand in the context of the problem with the units in thousands of USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: -40.91 (+/- 30.22) MSE\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, random_state=47)\n",
    "\n",
    "results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "print('Baseline: %.2f (+/- %.2f) MSE' %(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "It gives us an estimate of the model’s performance on the problem for unseen data. The result reports the MSE including the average and standard deviation(average variance) across all 10 folds of the cross-validation evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -13.41400992,  -21.91132667,   -5.73191913,  -40.80643153,\n",
       "        -51.79660368,  -32.1905456 ,  -27.92281556,  -85.77527382,\n",
       "       -105.15807104,  -24.37787559])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results #?????????????????????????????????????????????????? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Lift Performance By Standardizing The Dataset\n",
    "An important concern with the Boston house price dataset is that the input attributes all vary in their scales because they measure different quantities. It is almost always good practice to prepare your data before modeling it using a neural network model. Continuing on from the above baseline model, we can re-evaluate the same model using a **standardized version of the input dataset**. We can use scikit-learn’s **Pipeline** framework to perform the **standardization during the model evaluation process, within each fold of the cross-validation**. This ensures that there is no data leakage from each testset cross-validation fold into the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: -28.83 (+/- 28.04) MSE\n"
     ]
    }
   ],
   "source": [
    "# Regression Example With Boston Dataset: Standardized\n",
    "# evaluate model with standardized dataset\n",
    "estimators = [] \n",
    "estimators.append(('standardize', StandardScaler())) \n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0))) \n",
    "\n",
    "pipeline = Pipeline(estimators) \n",
    "kfold = KFold(n_splits=10, random_state=47) \n",
    "\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "print('Standardized: %.2f (+/- %.2f) MSE' %(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "A further extension of this section would be to similarly apply a rescaling to the output variable such as normalizing it to the range of 0 to 1 and use a Sigmoid or similar activation function on the output layer to narrow output predictions to the same range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tune The Topology\n",
    "There are many concerns that can be optimized for a neural network model. Perhaps the point of biggest leverage is the structure of the network itself, including the number of layers and the number of neurons in each layer. In this section we will evaluate two additional network topologies in an effort to further improve the performance of the model. \n",
    "- go deeper \n",
    "  - One way to improve the performance of a neural network is to add more layers. This might allow the model to extract and recombine higher order features embedded in the data. In this section we will evaluate the effect of **adding one more hidden layer** to the model. \n",
    "- go wider\n",
    "  - Another approach to increasing the representational capacity of the model is to create a wider network. In this section we evaluate the effect of keeping a shallow network architecture and nearly **doubling the number of neurons in the one hidden layer**. Here, we have increased the number of neurons in the hidden layer compared to the baseline model from 13 to 20.\n",
    "  \n",
    "It is hard to guess that a wider network would outperform a deeper network on this problem. The results demonstrate the importance of empirical testing when it comes to developing neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deeper: -22.63 (+/- 26.12) MSE\n"
     ]
    }
   ],
   "source": [
    "# go deeper (13 inputs -> 13 hidden -> 6 hidden -> 1 output)\n",
    "def deeper_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(6, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return(model)\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler())) \n",
    "estimators.append(('mlp', KerasRegressor(build_fn=deeper_model, epochs=50, batch_size=5, verbose=0))) \n",
    "pipeline = Pipeline(estimators) \n",
    "kfold = KFold(n_splits=10, random_state=47) \n",
    "results = cross_val_score(pipeline, X, y, cv=kfold) \n",
    "print(\"Deeper: %.2f (+/- %.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows a further improvement in MSE performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deeper: -24.43 (+/- 22.70) MSE\n"
     ]
    }
   ],
   "source": [
    "# go wider (13 inputs -> 20 hidden -> 1 output)\n",
    "def wider_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=13, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return(model)\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler())) \n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=50, batch_size=5, verbose=0))) \n",
    "pipeline = Pipeline(estimators) \n",
    "kfold = KFold(n_splits=10, random_state=47) \n",
    "results = cross_val_score(pipeline, X, y, cv=kfold) \n",
    "print(\"Deeper: %.2f (+/- %.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Building the model does see a further drop in error to about 24 thousand squared dollars!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
